#!/usr/bin/env python
from enum import Enum
from pathlib import Path
from subprocess import run
import os
import typer
from typing_extensions import Annotated


class ModelName(str, Enum):
    all_MiniLM_L6_v2 = "all-MiniLM-L6-v2"
    modernbert_msmarco = "joe32140/ModernBERT-base-msmarco"
    modernbert_base = "answerdotai/ModernBERT-base"
    modernbert_embed = "nomic-ai/modernbert-embed-base"
    nomic_embed = "nomic-ai/nomic-embed-text-v2-moe"


def main(
    model_name: Annotated[
        ModelName, typer.Option(help="Model name")
    ] = ModelName.nomic_embed,
    dry_run: Annotated[bool, typer.Option(help="Dry run")] = True,
):
    """A wrapper script for embedding sbatch scripts.

    It's recommended to manually run the commands that are printed out during
    the dry run. This gives more control over parallelism, especially given that
    we have a limited number of jobs that can be queued up. We can run 50 jobs,
    and for some of these larger models we need to split up the jobs into chunks
    of 50 to finish within the pre-emption deadline.
    """
    sbatch_script = (
        "sbatch/slurm-embed.sbatch"
        if model_name in ["all-MiniLM-L6-v2"]
        else "sbatch/slurm-embed-large.sbatch"
    )
    home = Path(os.environ["HOME"])
    root = home / "shared/longeval/2025/parquet"
    paths = sorted(
        [
            path.relative_to(root)
            for path in Path(root).glob("**/*")
            if "Documents" in path.parts
            and path.is_dir()
            and path.name.startswith("date=")
            and "_temporary" not in path.parts
        ]
    )
    for path in paths:
        cmd = [
            "sbatch",
            f"--job-name=longeval-embed_{model_name}_{path}",
            f"{Path(__file__).parent.parent}/{sbatch_script}",
            path.as_posix(),
            model_name,
        ]
        print(" ".join(cmd))
        if not dry_run:
            run(cmd)


if __name__ == "__main__":
    typer.run(main)
