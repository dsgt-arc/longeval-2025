{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a60ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9c86eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/19 16:24:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/19 16:24:42 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- rel: integer (nullable = true)\n",
      " |-- split: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from longeval.spark import get_spark\n",
    "from longeval.collection import ParquetCollection\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark(cores=8, memory=\"20g\")\n",
    "\n",
    "data_root = Path(\"~/shared/longeval/2025/parquet/\").expanduser()\n",
    "train = ParquetCollection(spark, data_root)\n",
    "train.queries.printSchema()\n",
    "train.qrels.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fb941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/19 16:24:56 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- contents: string (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- split: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+\n",
      "|summary|    docid|             count|\n",
      "+-------+---------+------------------+\n",
      "|  count|  3436116|           3436116|\n",
      "|   mean|     NULL| 5.529667799340884|\n",
      "| stddev|     NULL|4.0605147611216585|\n",
      "|    min|     doc1|                 1|\n",
      "|    25%|     NULL|                 3|\n",
      "|    50%|     NULL|                 5|\n",
      "|    75%|     NULL|                 8|\n",
      "|    max|doc999999|               311|\n",
      "+-------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's double check assumptions about overlap in the data\n",
    "train.documents.printSchema()\n",
    "train.documents.groupBy(\"docid\").count().summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b4d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================================================>  (596 + 8) / 623]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   date|  count|\n",
      "+-------+-------+\n",
      "|2022-06|1775681|\n",
      "|2022-07|1777616|\n",
      "|2022-08|1787018|\n",
      "|2022-09|1210186|\n",
      "|2022-10|2418103|\n",
      "|2022-11|2433787|\n",
      "|2022-12|2534242|\n",
      "|2023-01|2537565|\n",
      "|2023-02|2526382|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train.documents.groupBy(\"date\").count().orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df831cdf",
   "metadata": {},
   "source": [
    "So this analysis tells us that we should be building a different index for each of the dates. Each document also appears at different dates.\n",
    "\n",
    "There are other things that we might want to detect -- is a page english or is it french? This is from a french internet index, but I'm pretty sure most of the content on the internet is english anyways. \n",
    "\n",
    "Regardless, the thing is super slow right now because there are a lot of documents. Here we're still working with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72009798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "/storage/home/hcoda1/8/amiyaguchi3/clef/longeval-2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- qid: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- qrel: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = false)\n",
      " |    |    |-- docid: string (nullable = true)\n",
      " |    |    |-- rel: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+--------------------+\n",
      "|   date| qid|               query|                qrel|\n",
      "+-------+----+--------------------+--------------------+\n",
      "|2022-09|   1|        101boyvideos|[{20007, 0}, {273...|\n",
      "|2022-10|  10|    a vendre chateau|[{1592834, 0}, {1...|\n",
      "|2022-08| 100|   appli pole emploi|[{7753, 0}, {3619...|\n",
      "|2022-07|1000|ent mon bureau nu...|[{10529, 1}, {749...|\n",
      "|2022-10|1000|ent mon bureau nu...|[{7496, 2}, {1052...|\n",
      "+-------+----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from longeval.experiment.bm25.evaluation import (\n",
    "    prepare_queries,\n",
    "    run_search,\n",
    "    score_search,\n",
    ")\n",
    "\n",
    "queries = prepare_queries(train)\n",
    "queries.printSchema()\n",
    "queries.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c9c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/19 16:57:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/04/19 16:57:19 WARN TaskSetManager: Stage 60 contains a task of very large size (2364 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/19 16:57:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{Row(date='2022-06'): DataFrame[map: double, ndcg: double, ndcg_cut_10: double, ndcg_rel: double, qid: string],\n",
       " '2022-06': DataFrame[map: double, ndcg: double, ndcg_cut_10: double, ndcg_rel: double, qid: string]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_path = Path(\"~/scratch/longeval/temp/bm25/index\").expanduser().as_posix()\n",
    "\n",
    "date = queries.select(\"date\").distinct().orderBy(\"date\").first().date\n",
    "search_df = run_search(queries.where(f\"date='{date}'\"), index_path, k=100)\n",
    "eval_df = score_search(search_df)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d17615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----------+--------+-----+\n",
      "|map|ndcg|ndcg_cut_10|ndcg_rel|  qid|\n",
      "+---+----+-----------+--------+-----+\n",
      "|0.0| 0.0|        0.0|     0.0|10010|\n",
      "|0.0| 0.0|        0.0|     0.0|10012|\n",
      "|0.0| 0.0|        0.0|     0.0|10038|\n",
      "|0.0| 0.0|        0.0|     0.0|10077|\n",
      "|0.0| 0.0|        0.0|     0.0| 1008|\n",
      "|0.0| 0.0|        0.0|     0.0|10088|\n",
      "|0.0| 0.0|        0.0|     0.0|10096|\n",
      "|0.0| 0.0|        0.0|     0.0|10104|\n",
      "|0.0| 0.0|        0.0|     0.0|10114|\n",
      "|0.0| 0.0|        0.0|     0.0| 1012|\n",
      "|0.0| 0.0|        0.0|     0.0|10124|\n",
      "|0.0| 0.0|        0.0|     0.0|10133|\n",
      "|0.0| 0.0|        0.0|     0.0|10138|\n",
      "|0.0| 0.0|        0.0|     0.0|10177|\n",
      "|0.0| 0.0|        0.0|     0.0|10179|\n",
      "|0.0| 0.0|        0.0|     0.0|10191|\n",
      "|0.0| 0.0|        0.0|     0.0|10195|\n",
      "|0.0| 0.0|        0.0|     0.0|10203|\n",
      "|0.0| 0.0|        0.0|     0.0| 1021|\n",
      "|0.0| 0.0|        0.0|     0.0|10250|\n",
      "+---+----+-----------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
