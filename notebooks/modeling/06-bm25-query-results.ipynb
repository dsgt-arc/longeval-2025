{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a60ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9c86eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/22 11:11:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/22 11:11:38 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- rel: integer (nullable = true)\n",
      " |-- split: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from longeval.spark import get_spark\n",
    "from longeval.collection import ParquetCollection\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark(cores=8, memory=\"20g\")\n",
    "\n",
    "data_root = Path(\"~/shared/longeval/2025/parquet/\").expanduser()\n",
    "train = ParquetCollection(spark, data_root)\n",
    "train.queries.printSchema()\n",
    "train.qrels.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fb941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- contents: string (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- split: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   date|  count|\n",
      "+-------+-------+\n",
      "|2022-06|1775681|\n",
      "|2022-07|1777616|\n",
      "|2022-08|1787018|\n",
      "|2022-09|1210186|\n",
      "|2022-10|2418103|\n",
      "|2022-11|2433787|\n",
      "|2022-12|2534242|\n",
      "|2023-01|2537565|\n",
      "|2023-02|2526382|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.documents.printSchema()\n",
    "train.documents.groupBy(\"date\").count().orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72009798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- total: long (nullable = true)\n",
      " |-- max_score: double (nullable = true)\n",
      " |-- docids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- scores: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- qrel: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- docid: string (nullable = true)\n",
      " |    |    |-- rel: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n",
      "+-----+-----+------------------+--------------------+--------------------+--------------------+-------+\n",
      "|  qid|total|         max_score|              docids|              scores|                qrel|   date|\n",
      "+-----+-----+------------------+--------------------+--------------------+--------------------+-------+\n",
      "|10006|  100| 9.093899726867676|[doc1688336, doc1...|[9.09389972686767...|[{2867767, 2}, {1...|2023-01|\n",
      "| 1001|  100|10.286600112915039|[doc3356420, doc1...|[10.2866001129150...|[{1642418, 1}, {7...|2023-01|\n",
      "|10017|  100| 9.842000007629395|[doc3348809, doc3...|[9.84200000762939...|[{1678573, 1}, {1...|2023-01|\n",
      "+-----+-----+------------------+--------------------+--------------------+--------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_root = Path(\"~/shared/longeval/2025/bm25/retrieval\").expanduser()\n",
    "retrieval = spark.read.parquet(retrieval_root.as_posix())\n",
    "retrieval.printSchema()\n",
    "retrieval.show(n=3)\n",
    "retrieval.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61539013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- contents: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# zip docids scores and qres into a single column\n",
    "joined = (\n",
    "    retrieval.withColumn(\"zipped\", F.arrays_zip(\"docids\", \"scores\"))\n",
    "    .select(\"qid\", \"date\", F.explode(\"zipped\").alias(\"zipped\"))\n",
    "    .select(\n",
    "        \"qid\",\n",
    "        \"date\",\n",
    "        F.col(\"zipped.docids\").alias(\"docid\"),\n",
    "        F.col(\"zipped.scores\").alias(\"score\"),\n",
    "    )\n",
    "    .join(\n",
    "        train.documents.select(\"docid\", \"date\", \"contents\"),\n",
    "        on=[\"docid\", \"date\"],\n",
    "    )\n",
    "    .join(\n",
    "        train.queries.select(\"qid\", \"query\"),\n",
    "        on=[\"qid\"],\n",
    "    )\n",
    ")\n",
    "joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                 (0 + 1) / 1][Stage 33:============> (574 + 7) / 623]\r"
     ]
    }
   ],
   "source": [
    "joined.write.partitionBy(\"date\").parquet(\n",
    "    Path(\"~/shared/longeval/2025/bm25/retrieval_joined\").expanduser().as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
