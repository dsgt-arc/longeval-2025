{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/15 08:05:21 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from longeval.spark import get_spark\n",
    "from longeval.collection import ParquetCollection\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = get_spark()\n",
    "root = \"../../tests/integration\"\n",
    "collection = ParquetCollection(spark, f\"{root}/parquet/train/2023_01/English\")\n",
    "collection.queries.printSchema()\n",
    "collection.queries.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(qid='q0123805', query='Veal filet mignon')\n",
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- docid: string (nullable = true)\n",
      " |-- rel: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc012303512545',\n",
       " 'doc012304816815',\n",
       " 'doc012305205106',\n",
       " 'doc012307703830',\n",
       " 'doc012308900581',\n",
       " 'doc012312602366'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = collection.queries.sample(False, 0.1, 42).head()\n",
    "print(row)\n",
    "\n",
    "collection.qrels.printSchema()\n",
    "df = collection.qrels.where(F.col(\"qid\") == row.qid)\n",
    "df.count(), df.distinct().count()\n",
    "relevant_set = {row.docid for row in df.collect() if row.rel > 0}\n",
    "relevant_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doc012300800010', 'doc012306300006']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "client = OpenSearch(\"http://localhost:9200\")\n",
    "client.indices.get(index=\"train-english-2023_01\")\n",
    "\n",
    "query = row.query\n",
    "results = client.search(\n",
    "    index=\"train-english-2023_01\",\n",
    "    body={\"query\": {\"match\": {\"contents\": query}}},\n",
    "    size=1000,\n",
    ")\n",
    "docids = [hit[\"_source\"][\"docid\"] for hit in results[\"hits\"][\"hits\"]]\n",
    "print(docids[:10])\n",
    "true_relevance = [1 if docid in relevant_set else 0 for docid in docids]\n",
    "predicted_relevance = [1] * len(docids)\n",
    "ndcg_score([true_relevance], [predicted_relevance]), sum(true_relevance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
