{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/24 14:17:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from longeval.spark import get_spark\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================================>                  (16 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+----------+---------------+------+-----+\n",
      "|language|   date|split|collection|             id|tokens|words|\n",
      "+--------+-------+-----+----------+---------------+------+-----+\n",
      "|  French|2023_08| test| documents|doc082302214482|   379|  176|\n",
      "|  French|2023_08| test| documents|doc082302205059|  1909| 1183|\n",
      "|  French|2023_08| test| documents|doc082302200515|   264|  168|\n",
      "|  French|2023_08| test| documents|doc082302211708|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082302204885|  1542| 1151|\n",
      "|  French|2023_08| test| documents|doc082301205404|   374|  232|\n",
      "|  French|2023_08| test| documents|doc082302217498|   830|  490|\n",
      "|  French|2023_08| test| documents|doc082301218918|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082302204786|  1941| 1546|\n",
      "|  French|2023_08| test| documents|doc082301209434|  1156|  928|\n",
      "|  French|2023_08| test| documents|doc082301200421|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082301200369|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082301201472|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082302217142|   203|  109|\n",
      "|  French|2023_08| test| documents|doc082302201447|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082302215590|     0|    1|\n",
      "|  French|2023_08| test| documents|doc082301216992|  1318|  859|\n",
      "|  French|2023_08| test| documents|doc082301215388|  1458|  934|\n",
      "|  French|2023_08| test| documents|doc082301219137|  2046| 1645|\n",
      "|  French|2023_08| test| documents|doc082301218485|  2115| 1445|\n",
      "+--------+-------+-----+----------+---------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"../../data/longeval/tokens/*/*/*\").cache()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----------+-------+-------------+----------+-------------+------------+\n",
      "|split|language|collection|   date|   sum_tokens| sum_words|sum_tokens_pm|sum_words_pm|\n",
      "+-----+--------+----------+-------+-------------+----------+-------------+------------+\n",
      "| test|  French| documents|2023_08|1.761001846E9|1130451326|  1761.001846| 1130.451326|\n",
      "| test| English| documents|2023_08|1.648139339E9| 932733087|  1648.139339|  932.733087|\n",
      "|train|  French| documents|2023_01|2.557447888E9|1640616023|  2557.447888| 1640.616023|\n",
      "|train| English| documents|2023_01|2.375897725E9|1344163168|  2375.897725| 1344.163168|\n",
      "| test|  French| documents|2023_06|1.815450509E9|1163542559|  1815.450509| 1163.542559|\n",
      "| test| English| documents|2023_06|1.693284689E9| 960832171|  1693.284689|  960.832171|\n",
      "+-----+--------+----------+-------+-------------+----------+-------------+------------+\n",
      "\n",
      "+-----+--------+-------------+----------+-------------+------------+\n",
      "|split|language|   sum_tokens| sum_words|sum_tokens_pm|sum_words_pm|\n",
      "+-----+--------+-------------+----------+-------------+------------+\n",
      "| test|  French|3.576452355E9|2293993885|  3576.452355| 2293.993885|\n",
      "| test| English|3.341424028E9|1893565258|  3341.424028| 1893.565258|\n",
      "|train|  French|2.557447888E9|1640616023|  2557.447888| 1640.616023|\n",
      "|train| English|2.375897725E9|1344163168|  2375.897725| 1344.163168|\n",
      "+-----+--------+-------------+----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.where(F.col(\"collection\") == \"documents\")\n",
    "    .groupBy(\"split\", \"language\", \"collection\", \"date\")\n",
    "    .agg(\n",
    "        F.sum(\"tokens\").alias(\"sum_tokens\"),\n",
    "        F.sum(\"words\").alias(\"sum_words\"),\n",
    "    )\n",
    "    # divided by 1m\n",
    "    .withColumn(\"sum_tokens_pm\", F.col(\"sum_tokens\") / 1_000_000)\n",
    "    .withColumn(\"sum_words_pm\", F.col(\"sum_words\") / 1_000_000)\n",
    ").show()\n",
    "\n",
    "(\n",
    "    df.where(F.col(\"collection\") == \"documents\")\n",
    "    .groupBy(\"split\", \"language\")\n",
    "    .agg(\n",
    "        F.sum(\"tokens\").alias(\"sum_tokens\"),\n",
    "        F.sum(\"words\").alias(\"sum_words\"),\n",
    "    )\n",
    "    # divided by 1m\n",
    "    .withColumn(\"sum_tokens_pm\", F.col(\"sum_tokens\") / 1_000_000)\n",
    "    .withColumn(\"sum_words_pm\", F.col(\"sum_words\") / 1_000_000)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OpenAI embedding models: https://openai.com/api/pricing/\n",
    "\n",
    "| Model                | Pricing          | Pricing with Batch API* |\n",
    "|----------------------|------------------|-------------------------|\n",
    "| text-embedding-3-small | $0.020 / 1M tokens | $0.010 / 1M tokens      |\n",
    "| text-embedding-3-large | $0.130 / 1M tokens | $0.065 / 1M tokens      |\n",
    "| ada v2               | $0.100 / 1M tokens | $0.050 / 1M tokens      |\n",
    "\n",
    "For GCP: https://cloud.google.com/vertex-ai/generative-ai/pricing\n",
    "\n",
    "| Model               | Type  | Region | Price per 1,000 characters |\n",
    "|---------------------|-------|--------|----------------------------|\n",
    "| Embeddings for Text | Input | Global |                            |\n",
    "|                     |       |        | Online requests: $0.000025 |\n",
    "|                     |       |        | Batch requests: $0.00002   |\n",
    "\n",
    "For every million characters:\n",
    "\n",
    "| Model               | Type  | Region | Price per 1 million characters |\n",
    "|---------------------|-------|--------|----------------------------|\n",
    "| Embeddings for Text | Input | Global |                            |\n",
    "|                     |       |        | Online requests: $25       |\n",
    "|                     |       |        | Batch requests: $20        |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
